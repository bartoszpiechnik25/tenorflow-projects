{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rice Clasisfication\n",
    "\n",
    "Given dataset from kaggle with rice images we are going to create Convolutional Neural Network to detect different rice types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_PATH = os.path.join(os.getcwd(), 'data/')\n",
    "RICE_PATH = os.path.join(DATA_PATH, 'rice_dataset/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "Preprocess data and create train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = os.path.join(RICE_PATH, 'archive.zip')\n",
    "\n",
    "zip_file = zipfile.ZipFile(zip_path, 'r')\n",
    "zip_file.extractall(RICE_PATH)\n",
    "zip_file.close()\n",
    "os.remove(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Karacadag': 15000, 'Arborio': 15000, 'Jasmine': 15000, 'Ipsala': 15000, 'Basmati': 15000}\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(RICE_PATH, 'Rice_Image_Dataset/')\n",
    "\n",
    "def data_counter(path):\n",
    "    \"\"\"\n",
    "    Counts images in each directory\n",
    "\n",
    "    Args:\n",
    "      -path (string): directory path containing images\n",
    "    \n",
    "    Returns:\n",
    "      Dictionary containing directory names as keys and number of\n",
    "      files in directory as values.\n",
    "    \"\"\"\n",
    "    directory = os.listdir(path)\n",
    "    values = {directory[i]: 0 for i in range(len(directory))}\n",
    "    for folder in directory:\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        for img in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img)\n",
    "            if os.path.getsize(img_path) == 0:\n",
    "                os.remove(img_path)\n",
    "            else:\n",
    "                values[folder] += 1\n",
    "\n",
    "    return values\n",
    "\n",
    "print(data_counter(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random image size from Karacadag directory is: ((250, 250), 'RGB')\n",
      "Random image size from Arborio directory is: ((250, 250), 'RGB')\n",
      "Random image size from Jasmine directory is: ((250, 250), 'RGB')\n",
      "Random image size from Ipsala directory is: ((250, 250), 'RGB')\n",
      "Random image size from Basmati directory is: ((250, 250), 'RGB')\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from random import sample\n",
    "\n",
    "def print_size(dir):\n",
    "    \"\"\"\n",
    "    Print size of random image from each directory\n",
    "\n",
    "    Args:\n",
    "      -dir (string): directory path containing images\n",
    "    \n",
    "    Returns:\n",
    "      None\n",
    "    \"\"\"\n",
    "    for directory in os.listdir(dir):\n",
    "        directory_path = os.path.join(dir, directory)\n",
    "        image_p = sample(os.listdir(directory_path), 1)[0]\n",
    "        image = Image.open(os.path.join(directory_path, image_p))\n",
    "        print(f\"Random image size from {directory} directory is: {image.size, image.mode}\")\n",
    "\n",
    "\n",
    "print_size(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directories:\n",
      "-Karacadag\n",
      "-Arborio\n",
      "-Jasmine\n",
      "-Ipsala\n",
      "-Basmati\n",
      "\n",
      "Training sizes: {'Karacadag': 13500, 'Arborio': 13500, 'Jasmine': 13500, 'Ipsala': 13500, 'Basmati': 13500}\n",
      "\n",
      "Validation sizes: {'Karacadag': 1500, 'Arborio': 1500, 'Jasmine': 1500, 'Ipsala': 1500, 'Basmati': 1500}\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "def create_train_validation(data_path, training_path, validation_path, split_s):\n",
    "    \"\"\"\n",
    "    Split the data into train and validation datasets\n",
    "\n",
    "    Args:\n",
    "      -data_path (string): directory path containing images\n",
    "      -training_path (string): directory path to be used for training\n",
    "      -validation_path (string): directory path to be used for validation\n",
    "      -split_s (float): portion of the dataset to be used for training\n",
    "\n",
    "    Returns:\n",
    "      None\n",
    "    \"\"\"\n",
    "\n",
    "    dirs = os.listdir(data_path)\n",
    "    print(\"Data directories:\")\n",
    "    for img in dirs:\n",
    "        print(f'-{img}')\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(training_path)\n",
    "    except FileExistsError:\n",
    "        print('\\nTraining directory exists in this path')\n",
    "\n",
    "    try:\n",
    "        os.makedirs(validation_path)\n",
    "    except FileExistsError:\n",
    "        print('Validation directory exists in this path')\n",
    "\n",
    "    direcotries_sizes = data_counter(data_path)\n",
    "    \n",
    "    for dir in dirs:\n",
    "        train_name = os.path.join(training_path, dir)\n",
    "        validation_name = os.path.join(validation_path, dir)\n",
    "        os.makedirs(train_name)\n",
    "        os.makedirs(validation_name)\n",
    "        split = int(direcotries_sizes[dir] * split_s)\n",
    "        \n",
    "        curr_dir = os.path.join(data_path, dir)\n",
    "        dir_shuffled = sample(os.listdir(curr_dir), len(os.listdir(curr_dir)))\n",
    "\n",
    "        for img in dir_shuffled[:split]:\n",
    "            copyfile(os.path.join(curr_dir, img), os.path.join(train_name, img))\n",
    "        \n",
    "        for img in dir_shuffled[split:]:\n",
    "            copyfile(os.path.join(curr_dir, img), os.path.join(validation_name, img))\n",
    "    \n",
    "    print(f'\\nTraining sizes: {data_counter(training_path)}')\n",
    "    print(f'\\nValidation sizes: {data_counter(validation_path)}')\n",
    "\n",
    "    return training_path, validation_path    \n",
    "\n",
    "    \n",
    "training_path, validation_path  = create_train_validation(dataset_path, os.path.join(dataset_path, 'training/'), os.path.join(dataset_path, 'validation/'), .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.preprocesssing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/barti/deep/tenorflow-projects/rice_kaggle.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/barti/deep/tenorflow-projects/rice_kaggle.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocesssing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageDataGenerator\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.preprocesssing'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def cra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "524e827a62e851a22504cb633a8b21e398dd8e48b4ad2b53360e28277efb9acc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
