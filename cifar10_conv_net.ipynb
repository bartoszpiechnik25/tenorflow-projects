{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cifar10 convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset training size X=(50000, 32, 32, 3), Y=(50000, 1), validation size X=30720000, Y=(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset training size X={X_train.shape}, Y={y_train.shape}, validation size X={X_test.size}, Y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train / 255\n",
    "X_test_scaled =  X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique output are: [0 1 2 3 4 5 6 7 8 9], where every number represents different class\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique output are: {np.unique(y_train)}, where every number represents different class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10, dtype=np.float32)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 1.8633 - accuracy: 0.3251 - val_loss: 1.6051 - val_accuracy: 0.4196\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 1.4503 - accuracy: 0.4860 - val_loss: 1.3957 - val_accuracy: 0.5044\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 1.2350 - accuracy: 0.5661 - val_loss: 1.2809 - val_accuracy: 0.5535\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 1.0860 - accuracy: 0.6223 - val_loss: 1.2649 - val_accuracy: 0.5699\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.9616 - accuracy: 0.6648 - val_loss: 1.1280 - val_accuracy: 0.6093\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.8548 - accuracy: 0.7026 - val_loss: 1.0376 - val_accuracy: 0.6370\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.7575 - accuracy: 0.7356 - val_loss: 1.1118 - val_accuracy: 0.6207\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.6672 - accuracy: 0.7674 - val_loss: 1.0219 - val_accuracy: 0.6577\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.5890 - accuracy: 0.7969 - val_loss: 1.0839 - val_accuracy: 0.6464\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4988 - accuracy: 0.8262 - val_loss: 1.0273 - val_accuracy: 0.6706\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4215 - accuracy: 0.8529 - val_loss: 1.1706 - val_accuracy: 0.6614\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3542 - accuracy: 0.8772 - val_loss: 1.2302 - val_accuracy: 0.6645\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.2972 - accuracy: 0.8965 - val_loss: 1.2100 - val_accuracy: 0.6832\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.2507 - accuracy: 0.9128 - val_loss: 1.4555 - val_accuracy: 0.6631\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2148 - accuracy: 0.9276 - val_loss: 1.4456 - val_accuracy: 0.6715\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1772 - accuracy: 0.9385 - val_loss: 1.6433 - val_accuracy: 0.6633\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1534 - accuracy: 0.9466 - val_loss: 1.7451 - val_accuracy: 0.6536\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1355 - accuracy: 0.9537 - val_loss: 1.9911 - val_accuracy: 0.6654\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1226 - accuracy: 0.9587 - val_loss: 1.8194 - val_accuracy: 0.6768\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1155 - accuracy: 0.9612 - val_loss: 2.0240 - val_accuracy: 0.6874\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.1042 - accuracy: 0.9651 - val_loss: 2.0953 - val_accuracy: 0.6568\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9676 - val_loss: 2.3018 - val_accuracy: 0.6639\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0922 - accuracy: 0.9686 - val_loss: 2.2380 - val_accuracy: 0.6762\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0867 - accuracy: 0.9717 - val_loss: 2.1027 - val_accuracy: 0.6678\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0862 - accuracy: 0.9711 - val_loss: 2.2706 - val_accuracy: 0.6529\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0794 - accuracy: 0.9737 - val_loss: 2.3311 - val_accuracy: 0.6733\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0742 - accuracy: 0.9749 - val_loss: 2.5561 - val_accuracy: 0.6587\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0773 - accuracy: 0.9747 - val_loss: 2.5217 - val_accuracy: 0.6419\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0715 - accuracy: 0.9760 - val_loss: 2.5665 - val_accuracy: 0.6435\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0695 - accuracy: 0.9777 - val_loss: 2.4964 - val_accuracy: 0.6852\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0683 - accuracy: 0.9785 - val_loss: 2.6884 - val_accuracy: 0.6600\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0661 - accuracy: 0.9793 - val_loss: 2.9048 - val_accuracy: 0.6613\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0655 - accuracy: 0.9786 - val_loss: 2.7242 - val_accuracy: 0.6748\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0627 - accuracy: 0.9810 - val_loss: 2.9602 - val_accuracy: 0.6739\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0651 - accuracy: 0.9789 - val_loss: 2.8115 - val_accuracy: 0.6674\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0619 - accuracy: 0.9810 - val_loss: 2.8988 - val_accuracy: 0.6719\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0581 - accuracy: 0.9819 - val_loss: 2.8734 - val_accuracy: 0.6563\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0556 - accuracy: 0.9829 - val_loss: 3.0896 - val_accuracy: 0.6726\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0603 - accuracy: 0.9811 - val_loss: 3.1680 - val_accuracy: 0.6782\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0561 - accuracy: 0.9824 - val_loss: 3.1063 - val_accuracy: 0.6665\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0570 - accuracy: 0.9829 - val_loss: 3.1766 - val_accuracy: 0.6762\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0559 - accuracy: 0.9829 - val_loss: 3.0067 - val_accuracy: 0.6723\n",
      "Epoch 43/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0530 - accuracy: 0.9840 - val_loss: 2.9347 - val_accuracy: 0.6716\n",
      "Epoch 44/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0518 - accuracy: 0.9839 - val_loss: 3.2868 - val_accuracy: 0.6641\n",
      "Epoch 45/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0526 - accuracy: 0.9842 - val_loss: 3.2104 - val_accuracy: 0.6657\n",
      "Epoch 46/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0510 - accuracy: 0.9852 - val_loss: 3.8074 - val_accuracy: 0.6506\n",
      "Epoch 47/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 3.3115 - val_accuracy: 0.6766\n",
      "Epoch 48/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0526 - accuracy: 0.9850 - val_loss: 3.0257 - val_accuracy: 0.6733\n",
      "Epoch 49/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 3.4528 - val_accuracy: 0.6799\n",
      "Epoch 50/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0506 - accuracy: 0.9856 - val_loss: 3.2577 - val_accuracy: 0.6791\n",
      "Epoch 51/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9858 - val_loss: 3.4169 - val_accuracy: 0.6688\n",
      "Epoch 52/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0477 - accuracy: 0.9865 - val_loss: 3.4440 - val_accuracy: 0.6779\n",
      "Epoch 53/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0465 - accuracy: 0.9863 - val_loss: 3.4511 - val_accuracy: 0.6788\n",
      "Epoch 54/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0459 - accuracy: 0.9870 - val_loss: 3.5694 - val_accuracy: 0.6586\n",
      "Epoch 55/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0433 - accuracy: 0.9871 - val_loss: 3.5186 - val_accuracy: 0.6593\n",
      "Epoch 56/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0450 - accuracy: 0.9865 - val_loss: 3.8306 - val_accuracy: 0.6579\n",
      "Epoch 57/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0423 - accuracy: 0.9874 - val_loss: 3.6571 - val_accuracy: 0.6682\n",
      "Epoch 58/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0474 - accuracy: 0.9864 - val_loss: 3.5983 - val_accuracy: 0.6708\n",
      "Epoch 59/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0428 - accuracy: 0.9885 - val_loss: 3.7985 - val_accuracy: 0.6704\n",
      "Epoch 60/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0436 - accuracy: 0.9877 - val_loss: 3.7491 - val_accuracy: 0.6730\n",
      "Epoch 61/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0432 - accuracy: 0.9876 - val_loss: 3.7982 - val_accuracy: 0.6761\n",
      "Epoch 62/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0404 - accuracy: 0.9883 - val_loss: 3.8107 - val_accuracy: 0.6713\n",
      "Epoch 63/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0429 - accuracy: 0.9883 - val_loss: 3.5031 - val_accuracy: 0.6706\n",
      "Epoch 64/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0404 - accuracy: 0.9886 - val_loss: 3.7936 - val_accuracy: 0.6804\n",
      "Epoch 65/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0425 - accuracy: 0.9884 - val_loss: 4.5627 - val_accuracy: 0.6383\n",
      "Epoch 66/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0392 - accuracy: 0.9886 - val_loss: 3.8343 - val_accuracy: 0.6638\n",
      "Epoch 67/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0423 - accuracy: 0.9882 - val_loss: 3.8166 - val_accuracy: 0.6855\n",
      "Epoch 68/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0388 - accuracy: 0.9892 - val_loss: 3.9746 - val_accuracy: 0.6703\n",
      "Epoch 69/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0394 - accuracy: 0.9891 - val_loss: 3.8231 - val_accuracy: 0.6846\n",
      "Epoch 70/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0411 - accuracy: 0.9889 - val_loss: 3.7731 - val_accuracy: 0.6836\n",
      "Epoch 71/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0401 - accuracy: 0.9884 - val_loss: 3.8577 - val_accuracy: 0.6853\n",
      "Epoch 72/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0379 - accuracy: 0.9887 - val_loss: 3.7444 - val_accuracy: 0.6785\n",
      "Epoch 73/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0396 - accuracy: 0.9889 - val_loss: 3.9872 - val_accuracy: 0.6827\n",
      "Epoch 74/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0400 - accuracy: 0.9898 - val_loss: 4.3295 - val_accuracy: 0.6532\n",
      "Epoch 75/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0383 - accuracy: 0.9896 - val_loss: 3.8165 - val_accuracy: 0.6755\n",
      "Epoch 76/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0382 - accuracy: 0.9902 - val_loss: 4.3716 - val_accuracy: 0.6589\n",
      "Epoch 77/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0365 - accuracy: 0.9903 - val_loss: 3.8820 - val_accuracy: 0.6798\n",
      "Epoch 78/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 4.0623 - val_accuracy: 0.6650\n",
      "Epoch 79/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0373 - accuracy: 0.9891 - val_loss: 4.1155 - val_accuracy: 0.6662\n",
      "Epoch 80/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0371 - accuracy: 0.9895 - val_loss: 4.3205 - val_accuracy: 0.6600\n",
      "Epoch 81/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0385 - accuracy: 0.9893 - val_loss: 4.1545 - val_accuracy: 0.6664\n",
      "Epoch 82/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0337 - accuracy: 0.9906 - val_loss: 3.8829 - val_accuracy: 0.6694\n",
      "Epoch 83/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 4.3718 - val_accuracy: 0.6774\n",
      "Epoch 84/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0359 - accuracy: 0.9901 - val_loss: 4.4635 - val_accuracy: 0.6761\n",
      "Epoch 85/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0387 - accuracy: 0.9906 - val_loss: 4.3757 - val_accuracy: 0.6696\n",
      "Epoch 86/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0329 - accuracy: 0.9910 - val_loss: 4.6458 - val_accuracy: 0.6480\n",
      "Epoch 87/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0365 - accuracy: 0.9910 - val_loss: 4.5499 - val_accuracy: 0.6790\n",
      "Epoch 88/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0359 - accuracy: 0.9907 - val_loss: 4.4077 - val_accuracy: 0.6777\n",
      "Epoch 89/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0337 - accuracy: 0.9910 - val_loss: 4.4330 - val_accuracy: 0.6848\n",
      "Epoch 90/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0319 - accuracy: 0.9917 - val_loss: 4.8148 - val_accuracy: 0.6725\n",
      "Epoch 91/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0352 - accuracy: 0.9907 - val_loss: 4.9209 - val_accuracy: 0.6637\n",
      "Epoch 92/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0336 - accuracy: 0.9910 - val_loss: 4.5653 - val_accuracy: 0.6674\n",
      "Epoch 93/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0315 - accuracy: 0.9913 - val_loss: 4.5370 - val_accuracy: 0.6788\n",
      "Epoch 94/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 4.9016 - val_accuracy: 0.6753\n",
      "Epoch 95/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9916 - val_loss: 4.6551 - val_accuracy: 0.6709\n",
      "Epoch 96/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0334 - accuracy: 0.9913 - val_loss: 4.5747 - val_accuracy: 0.6876\n",
      "Epoch 97/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 4.5394 - val_accuracy: 0.6795\n",
      "Epoch 98/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0319 - accuracy: 0.9919 - val_loss: 4.6237 - val_accuracy: 0.6792\n",
      "Epoch 99/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 4.6621 - val_accuracy: 0.6669\n",
      "Epoch 100/100\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.0308 - accuracy: 0.9919 - val_loss: 4.4323 - val_accuracy: 0.6821\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten, Layer, Conv2D, MaxPooling2D, Dense\n",
    "from keras import Sequential\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    simple_conv_model = Sequential([\n",
    "        Conv2D(32, (5,5), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'),\n",
    "        Conv2D(64, (5,5), strides=(1,1)),\n",
    "        MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'),\n",
    "        Flatten(),\n",
    "        Dense(400, activation='relu'),\n",
    "        Dense(120, activation='relu'),\n",
    "        Dense(40, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    simple_conv_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    simple_conv_model.fit(X_train_scaled, y_train_one_hot, batch_size=256, validation_data=(X_test_scaled, y_test_one_hot), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model evaluation is showing ENORMOUS overfitting after 100 epochs loss on train set is 0.03 wheras on validation set it is over 5. To prevent this we are going to apply dropout regularization and create EarlyStopping instance to stop learning after certain point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "simple_conv_model_v2 = Sequential([\n",
    "    Conv2D(32, (5,5)),\n",
    "    MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'),\n",
    "    Conv2D(64, (5,5), strides=(1,1)),\n",
    "    MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'),\n",
    "    Flatten(),\n",
    "    Dense(400, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(120, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(40, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "simple_conv_model_v2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('val_loss') - logs.get('loss') > 1.:\n",
    "            print(\"\\nDifference between val_loss and loss is bigger than 1!\")\n",
    "            self.model.stop_training = True\n",
    "        if logs.get('val_accuracy') - logs.get('accuracy') < -0.05:\n",
    "            print(\"\\nDifference between val_accuracy and train accuracy is bigger than -0.05!\")\n",
    "            self.model.stop_training = True\n",
    "callback = MyCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_17 (Conv2D)          (50000, 28, 28, 32)       2432      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (50000, 14, 14, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (50000, 10, 10, 64)       51264     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (50000, 5, 5, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (50000, 1600)             0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (50000, 400)              640400    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (50000, 400)              0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (50000, 120)              48120     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (50000, 120)              0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (50000, 40)               4840      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (50000, 40)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (50000, 10)               410       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 747,466\n",
      "Trainable params: 747,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_conv_model_v2.build(X_train_scaled.shape)\n",
    "simple_conv_model_v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - 2s 12ms/step - loss: 2.0880 - accuracy: 0.2286 - val_loss: 1.7311 - val_accuracy: 0.3941\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.7509 - accuracy: 0.3657 - val_loss: 1.4656 - val_accuracy: 0.4896\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.6052 - accuracy: 0.4253 - val_loss: 1.3772 - val_accuracy: 0.5273\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.4829 - accuracy: 0.4782 - val_loss: 1.2765 - val_accuracy: 0.5535\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.3924 - accuracy: 0.5146 - val_loss: 1.2063 - val_accuracy: 0.5840\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 1.3296 - accuracy: 0.5393 - val_loss: 1.1568 - val_accuracy: 0.6021\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.2767 - accuracy: 0.5604 - val_loss: 1.1477 - val_accuracy: 0.5949\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 1.2122 - accuracy: 0.5847 - val_loss: 1.1048 - val_accuracy: 0.6100\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.1702 - accuracy: 0.6028 - val_loss: 1.0685 - val_accuracy: 0.6305\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.1311 - accuracy: 0.6197 - val_loss: 1.0262 - val_accuracy: 0.6531\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.0874 - accuracy: 0.6313 - val_loss: 0.9974 - val_accuracy: 0.6629\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.0487 - accuracy: 0.6471 - val_loss: 0.9837 - val_accuracy: 0.6631\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 1.0318 - accuracy: 0.6516 - val_loss: 1.0131 - val_accuracy: 0.6537\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.9853 - accuracy: 0.6666 - val_loss: 0.9634 - val_accuracy: 0.6759\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.9464 - accuracy: 0.6818 - val_loss: 0.9478 - val_accuracy: 0.6826\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.9303 - accuracy: 0.6892 - val_loss: 0.9664 - val_accuracy: 0.6806\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.9010 - accuracy: 0.6988 - val_loss: 0.9468 - val_accuracy: 0.6843\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.8767 - accuracy: 0.7065 - val_loss: 0.9374 - val_accuracy: 0.6870\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.8607 - accuracy: 0.7124 - val_loss: 0.9495 - val_accuracy: 0.6794\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.8181 - accuracy: 0.7252 - val_loss: 0.9384 - val_accuracy: 0.6937\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.8122 - accuracy: 0.7294 - val_loss: 0.9372 - val_accuracy: 0.6909\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.7879 - accuracy: 0.7371 - val_loss: 0.9430 - val_accuracy: 0.6981\n",
      "Epoch 23/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.7682 - accuracy: 0.7441\n",
      "Difference between val_accuracy and train accuracy is bigger than -0.05!\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.7679 - accuracy: 0.7442 - val_loss: 0.9681 - val_accuracy: 0.6868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f52c1d31b80>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_conv_model_v2.fit(X_train_scaled,\n",
    "                        y_train_one_hot,\n",
    "                        epochs=100,\n",
    "                        batch_size=512,\n",
    "                        callbacks=[callback],\n",
    "                        validation_data=(X_test_scaled, y_test_one_hot),\n",
    "                        validation_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "524e827a62e851a22504cb633a8b21e398dd8e48b4ad2b53360e28277efb9acc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
